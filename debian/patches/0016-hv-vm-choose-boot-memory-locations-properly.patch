From: Helmut Buchsbaum <helmut.buchsbaum@opensource.tttech-industrial.com>
Date: Tue, 5 May 2020 20:34:59 +0200
Subject: hv: vm: choose boot memory locations properly

In order to place the images for SOS booting at correct locations
to avoid random crahes (depending on images loaded, bootloaders, boot
protocols) we need the to take into account the following information:

 * E820 memory map available for the SOS
 * memory already allocated by the bootloader
 * requirement imposed by the Linux bzImage according to the Linux boot
   protocol (LBP)

Remark: right now we only can handle bzImage Linux kernels

This is an example memory layout *AFTER* choosing the proper locations
directly at SOS kernel boot and this is dependent on how the bootloader
uses the available memory E820 memory map to load ACRN, boot info block
boot modules (bzImage, initramfs) and other boot protocol dependent data.
This will vary also on the chosen boot protocol: multiboot vs multiboot2.

 +-----------+ <-- memory top
 |XXXXXXXXXXX|
 |XXXXXXXXXXX|
     ....
 |XXXXXXXXXXX|
 |XXXXXXXXXXX|
 +-----------+ <-- LBP:initrd_addr_max (<=0x37FFFFFF)
 |           |
 |           |
 +-----------+
 |           |\
 |           | + <-- initramfs/initrd (at kernel boot time)
 |           |/
 +-----------+ <-- ramdisk_info.load_addr
 |XXXXXXXXXXX|
 |XXXXXXXXXXX|
 +-----------+
 |           |\
 | ACRN HV   | + <-- ACRN Hypervisor
 |           |/
 +-----------+
     ....
 |XXXXXXXXXXX|
 +-----------+
 | MBI DATA  | <-- Multiboot(2) Info Block Data
 +-----------+     (scattered across the avail. E820-RAM)
 |XXXXXXXXXXX|
 |XXXXXXXXXXX|
 +-----------+
 |           |\
 |           | |
 |           | |
 |           | |
 |           | + <-- bzImage (size derived from LBP:init_size)
 |           | |
 |           | |
 |           | |
 |           |/
 +-----------+ <-- kernel_info.kernel_load_addr (>=LBP:pref_addr>= 0x100000)
 |           |
 +-----------+ <-- zeropage (=kernel_info.kernel_load_addr-PAGE_SIZE)
 |           |
 +-----------+ <-- bootargs_info.load_addr (=kernel_info.kernel_load_addr-8k)
 |           |
 +-----------+ <-- initial SOS guest vGDT (=bootargs_info.load_addr-32)
 |XXXXXXXXXXX|
 |XXXXXXXXXXX|
     ....
 |XXXXXXXXXXX|
 |XXXXXXXXXXX|
 +-----------+
 |    MBI    | <-- Multiboot(2) Info Block
 +-----------+
 |XXXXXXXXXXX|
 +-----------+ <-- 0x0000000000000000

Signed-off-by: Helmut Buchsbaum <helmut.buchsbaum@opensource.tttech-industrial.com>
---
 hypervisor/arch/x86/guest/vm.c     | 109 +++++++++++++++++++++++++++++++++++--
 hypervisor/boot/guest/vboot_info.c | 102 +++++++++++++++++++++++++++++++---
 hypervisor/common/vm_load.c        |  48 +++++++++-------
 3 files changed, 227 insertions(+), 32 deletions(-)

diff --git a/hypervisor/arch/x86/guest/vm.c b/hypervisor/arch/x86/guest/vm.c
index 5acec6a..943dba1 100644
--- a/hypervisor/arch/x86/guest/vm.c
+++ b/hypervisor/arch/x86/guest/vm.c
@@ -33,6 +33,9 @@
 #include <vacpi.h>
 #include <platform_caps.h>
 
+#define ALIGN_UP(x, align)	(((x) + ((align)-1)) & ~((align)-1))
+#define ALIGN_DOWN(x, align)	((x) & ~((align)-1))
+
 vm_sw_loader_t vm_sw_loader;
 
 /* Local variables */
@@ -393,6 +396,99 @@ static uint64_t lapic_pt_enabled_pcpu_bitmap(struct acrn_vm *vm)
 	return bitmap;
 }
 
+static uint32_t sos_boot_mmap_num;
+static struct e820_entry sos_boot_mmap[2 * E820_MAX_ENTRIES];
+
+static void filter_mem_from_sos_boot_mmap(uint64_t start, uint64_t end)
+{
+	uint32_t i;
+
+	for (i = 0U; i < sos_boot_mmap_num; i++) {
+		struct e820_entry *entry = &sos_boot_mmap[i];
+		uint64_t entry_end = entry->baseaddr + entry->length;
+
+		/* No need handle in these cases, try next one */
+		if ((entry->type != E820_TYPE_RAM) ||
+		    (entry_end <= start) ||
+		    (entry->baseaddr > end)) {
+			continue;
+		}
+
+		/* This entry is within the range of specific memory
+		 * change to E820_TYPE_RESERVED
+		 */
+		if ((entry->baseaddr >= start) &&
+		    (end >= entry_end)) {
+			entry->type = E820_TYPE_RESERVED;
+			break;
+		}
+
+		/* cut head of entry */
+		if ((entry->baseaddr >= start) &&
+		    (end < entry_end)) {
+			entry->baseaddr = end;
+			entry->length = entry_end - end;
+			break;
+		}
+
+		/* cut tail of entry */
+		if ((entry->baseaddr < start) &&
+		    (end >= entry_end)) {
+			entry->length = start - entry->baseaddr;
+			break;
+		}
+
+		/* split entry */
+		if ((entry->baseaddr < start) &&
+		    (end <= entry_end)) {
+			entry->length = start - entry->baseaddr;
+			if (end == entry_end)
+				break;
+
+			ASSERT(sos_boot_mmap_num < ARRAY_SIZE(sos_boot_mmap),
+				"sos_boot_mmap overflow");
+			sos_boot_mmap[sos_boot_mmap_num].baseaddr = end;
+			sos_boot_mmap[sos_boot_mmap_num].length = entry_end - end;
+			sos_boot_mmap[sos_boot_mmap_num].type = E820_TYPE_RAM;
+			sos_boot_mmap_num++;
+			break;
+		}
+	}
+}
+
+static void create_sos_boot_mmap(struct acrn_vm *vm)
+{
+	uint32_t i, j, num;
+	struct multiboot_memory *mb_mem;
+
+	/* only RAM entries are required */
+	for (i = 0, j = 0; i < vm->e820_entry_num; ++i) {
+		if (vm->e820_entries[i].type != E820_TYPE_RAM)
+			continue;
+		sos_boot_mmap[j++] = vm->e820_entries[i];
+	}
+	sos_boot_mmap_num = j;
+
+	/* filter out all ranges occupied by bootloader data */
+	mb_mem = get_multiboot_used_memory(&num);
+	for (i = 0; i < num; ++i) {
+		filter_mem_from_sos_boot_mmap(ALIGN_DOWN(mb_mem[i].addr, PAGE_SIZE),
+			ALIGN_UP(mb_mem[i].addr + mb_mem[i].size, PAGE_SIZE));
+	}
+
+	/* sort sos_boot_mmap */
+	for (i = 0; i < sos_boot_mmap_num; ++i) {
+		for (j = 0; j < sos_boot_mmap_num; j++) {
+			if (sos_boot_mmap[j].baseaddr > sos_boot_mmap[i].baseaddr) {
+				struct e820_entry entry = sos_boot_mmap[i];
+
+				sos_boot_mmap[i] = sos_boot_mmap[j];
+				sos_boot_mmap[j] = entry;
+			}
+		}
+	}
+}
+
 /*
  * Allocate E820 ram for VM
  *
@@ -415,8 +511,8 @@ void *vm_allocate(struct acrn_vm *vm, uint32_t size, uint64_t pa_addr,
 
 	/* try to find the required section */
 	if (pa_addr != 0) {
-		for (i = 0; i < vm->e820_entry_num; ++i) {
-			struct e820_entry *e820 = &vm->e820_entries[i];
+		for (i = 0; i < sos_boot_mmap_num; ++i) {
+			struct e820_entry *e820 = &sos_boot_mmap[i];
 
 			/* no RAM section */
 			if (e820->type != E820_TYPE_RAM)
@@ -442,8 +538,8 @@ void *vm_allocate(struct acrn_vm *vm, uint32_t size, uint64_t pa_addr,
 	if (!relocatable)
 		return NULL;
 
-	for (i = 0; i < vm->e820_entry_num; ++i) {
-		struct e820_entry *e820 = &vm->e820_entries[i];
+	for (i = 0; i < sos_boot_mmap_num; ++i) {
+		struct e820_entry *e820 = &sos_boot_mmap[i];
 
 		/* no RAM section */
 		if (e820->type != E820_TYPE_RAM)
@@ -496,8 +592,8 @@ void *vm_allocate_top(struct acrn_vm *vm, uint32_t size, uint64_t max_end)
 	if (max_start < vm->boot_allocator_top)
 		goto out;
 
-	for (i = vm->e820_entry_num -1; i >= 0; --i) {
-		struct e820_entry *e820 = &vm->e820_entries[i];
+	for (i = sos_boot_mmap_num -1; i >= 0; --i) {
+		struct e820_entry *e820 = &sos_boot_mmap[i];
 		uint64_t entry_end = e820->baseaddr + e820->length;
 
 		/* no RAM section */
@@ -573,6 +669,7 @@ int32_t create_vm(uint16_t vm_id, uint64_t pcpu_bitmap, struct acrn_vm_config *v
 		/* Only for SOS_VM */
 		create_sos_vm_e820(vm);
 		prepare_sos_vm_memmap(vm);
+		create_sos_boot_mmap(vm);
 
 		status = init_vm_boot_info(vm);
 	} else {
diff --git a/hypervisor/boot/guest/vboot_info.c b/hypervisor/boot/guest/vboot_info.c
index 67c8096..dc9a479 100644
--- a/hypervisor/boot/guest/vboot_info.c
+++ b/hypervisor/boot/guest/vboot_info.c
@@ -22,21 +22,66 @@
 
 #define DBG_LEVEL_BOOT	6U
 
+/* TODO: move these to macros.h */
+#define ALIGN_UP(x, align)	(((x) + ((align)-1)) & ~((align)-1))
+#define ALIGN_DOWN(x, align)	((x) & ~((align)-1))
+
 #define MAX_BOOT_PARAMS_LEN 64U
 #define INVALID_MOD_IDX		0xFFFFU
 
+#define LINUX_BOOT_MAGIC	0xaa55U		/* Linux boot header magic */
+#define LINUX_HDRS_MAGIC	0x53726448U	/* Linux magic number 'HdrS' */
+
+/*
+ * default load address for Linux bzImage kernel according to
+ * Documentation/x86/boot.txt, see LOADING THE REST OF THE KERNEL
+ */
+#define LINUX_BZIMAGE_DEFAULT_ADDR	0x100000UL
+/* see Documentation/x86/boot.txt, initrd_addr_max */
+#define LINUX_INITRD_MAX_ADDRESS	0x37FFFFFF
+
+/* verify Linux bzImage boot header */
+static bool is_linux_kernel(const struct zero_page *zeropage)
+{
+	bool ret = true;
+
+	    /* check simple boot magic */
+	if ((zeropage->hdr.boot_flag != LINUX_BOOT_MAGIC) ||
+	    /* ignore really old kernels (< 1.3.73, no bzImage support) */
+	    (zeropage->hdr.version < 0x200) ||
+	    /* check "HdrS" magic */
+	    (zeropage->hdr.header != LINUX_HDRS_MAGIC) ||
+	    /* check for bzImage, i.e. LOAD_FLAG_LOADED_HIGH is set */
+	    ((zeropage->hdr.load_flags & LOAD_FLAG_LOADED_HIGH) == 0))
+		ret = false;
+
+	return ret;
+}
+
 /**
  * @pre vm != NULL && mbi != NULL
  */
 static void init_vm_ramdisk_info(struct acrn_vm *vm, const struct multiboot_module *mod)
 {
+	uint32_t size;
+	uint64_t addr_max = LINUX_INITRD_MAX_ADDRESS;
 	void *mod_addr = hpa2hva((uint64_t)mod->mm_mod_start);
+	const struct zero_page *zeropage = vm->sw.kernel_info.kernel_src_addr;
 
 	if ((mod_addr != NULL) && (mod->mm_mod_end > mod->mm_mod_start)) {
 		vm->sw.ramdisk_info.src_addr = mod_addr;
-		vm->sw.ramdisk_info.load_addr = vm->sw.kernel_info.kernel_load_addr + vm->sw.kernel_info.kernel_size;
-		vm->sw.ramdisk_info.load_addr = (void *)round_page_up((uint64_t)vm->sw.ramdisk_info.load_addr);
 		vm->sw.ramdisk_info.size = mod->mm_mod_end - mod->mm_mod_start;
+
+		size = ALIGN_UP(mod->mm_mod_end - mod->mm_mod_start, PAGE_SIZE);
+		if (zeropage->hdr.version >= 0x0203)
+			/* limit addr_max due to possibly bogus kernel value */
+			addr_max = min(zeropage->hdr.initrd_addr_max, addr_max);
+
+		/* needed due to bug in memory range check of Linux 2.2.xx */
+		addr_max -= 0x10000;
+
+		vm->sw.ramdisk_info.load_addr =
+			vm_allocate_top(vm, size, addr_max + 1);
 	}
 }
 
@@ -97,6 +142,9 @@ static void *get_kernel_load_addr(struct acrn_vm *vm)
 	void *load_addr = NULL;
 	struct vm_sw_info *sw_info = &vm->sw;
 	struct zero_page *zeropage;
+	uint64_t pref_addr;
+	uint32_t ksz;
+	uint32_t alignment;
 	struct acrn_vm_config *vm_config = get_vm_config(vm->vm_id);
 
 	switch (sw_info->kernel_type) {
@@ -110,13 +158,53 @@ static void *get_kernel_load_addr(struct acrn_vm *vm)
 		 * non-relocatable.
 		 */
 		zeropage = (struct zero_page *)sw_info->kernel_info.kernel_src_addr;
-		if (zeropage->hdr.relocatable_kernel != 0U) {
-			zeropage = (struct zero_page *)zeropage->hdr.pref_addr;
+		if (!is_linux_kernel(zeropage)) {
+			pr_err("Kernel image is not a valid bzImage!");
+			load_addr = NULL;
+			break;
+		}
+
+		/* get load address from Linux boot header */
+		if ((zeropage->hdr.version >= 0x020a) &&
+		    (zeropage->hdr.relocatable_kernel != 0U)) {
+			pref_addr = zeropage->hdr.pref_addr;
+		} else {
+			pref_addr = LINUX_BZIMAGE_DEFAULT_ADDR;
+		}
+
+		alignment = 0x200000;
+		/* respect physical address alignment */
+		if (zeropage->hdr.version >= 0x0205) {
+			alignment = zeropage->hdr.kernel_alignment;
 		}
-		load_addr = (void *)zeropage;
+		pref_addr = ALIGN_UP(pref_addr, alignment);
+
+		/* determine memory needs for kernel */
+		if (zeropage->hdr.version >= 0x020a)
+			ksz = ALIGN_UP(zeropage->hdr.init_size, PAGE_SIZE);
+		else
+			/*
+			 * Estimated compression ratio is approx 50%,
+			 * so make sure it fits
+			 */
+			ksz = 3 * ALIGN_UP(vm->sw.kernel_info.kernel_size,
+				PAGE_SIZE);
+
+		/*
+		 * reserve additional space to prepend  bootargs and zeropage
+		 * We use 4k for bootargs + 4k for zeropage + 32bytes for
+		 * initial vGDT: 0x1000 + 0x1000 + 0x20 -> 0x2020
+		 */
+		load_addr = vm_allocate(vm, ksz + ALIGN_UP(0x2020, alignment),
+			pref_addr - ALIGN_UP(0x2020, alignment),
+			zeropage->hdr.relocatable_kernel != 0U);
+		load_addr = (void *)ALIGN_UP((uint64_t)load_addr +
+			ALIGN_UP(0x2020, alignment), alignment);
+
 		break;
 	case KERNEL_ZEPHYR:
-		load_addr = (void *)vm_config->os_config.kernel_load_addr;
+		load_addr = vm_allocate(vm, vm->sw.kernel_info.kernel_size,
+			vm_config->os_config.kernel_load_addr, false);
 		break;
 	default:
 		pr_err("Unsupported Kernel type.");
@@ -177,7 +265,7 @@ static void init_vm_bootargs_info(struct acrn_vm *vm, const struct acrn_multiboo
 		}
 	}
 
-	/* Kernel bootarg and zero page are right before the kernel image */
+	/* Kernel bootarg and zero page are 8k right before the kernel image */
 	if (vm->sw.bootargs_info.size > 0U) {
 		vm->sw.bootargs_info.load_addr = vm->sw.kernel_info.kernel_load_addr - (MEM_1K * 8U);
 	} else {
diff --git a/hypervisor/common/vm_load.c b/hypervisor/common/vm_load.c
index de9b580..9bae9da 100644
--- a/hypervisor/common/vm_load.c
+++ b/hypervisor/common/vm_load.c
@@ -14,24 +14,18 @@
 #include <sprintf.h>
 #include <logmsg.h>
 
+/* TODO: move these to macros.h */
+#define ALIGN_UP(x, align)	(((x) + ((align)-1)) & ~((align)-1))
+
 #define NUM_REMAIN_1G_PAGES	3UL
 
-/*
- * We put the guest init gdt after kernel/bootarg/ramdisk images. Suppose this is a
- * safe place for guest init gdt of guest whatever the configuration is used by guest.
- */
-static uint64_t get_guest_gdt_base_gpa(const struct acrn_vm *vm)
+static uint64_t get_guest_gdt_base_gpa(struct acrn_vm *vm)
 {
-	uint64_t new_guest_gdt_base_gpa, guest_kernel_end_gpa, guest_bootargs_end_gpa, guest_ramdisk_end_gpa;
-
-	guest_kernel_end_gpa = (uint64_t)vm->sw.kernel_info.kernel_load_addr + vm->sw.kernel_info.kernel_size;
-	guest_bootargs_end_gpa = (uint64_t)vm->sw.bootargs_info.load_addr + vm->sw.bootargs_info.size;
-	guest_ramdisk_end_gpa = (uint64_t)vm->sw.ramdisk_info.load_addr + vm->sw.ramdisk_info.size;
-
-	new_guest_gdt_base_gpa = max(guest_kernel_end_gpa, max(guest_bootargs_end_gpa, guest_ramdisk_end_gpa));
-	new_guest_gdt_base_gpa = (new_guest_gdt_base_gpa + 7UL) & ~(8UL - 1UL);
-
-	return new_guest_gdt_base_gpa;
+	/*
+	 * locate initial guest GDT just before bootargs. The allocation was
+	 * done when allocating memory for bzImage
+	 */
+	return (uint64_t)vm->sw.bootargs_info.load_addr - 32;
 }
 
 /**
@@ -200,21 +194,37 @@ int32_t direct_boot_sw_loader(struct acrn_vm *vm)
 	init_vcpu_protect_mode_regs(vcpu, get_guest_gdt_base_gpa(vcpu->vm));
 
 	/* Copy the guest kernel image to its run-time location */
-	(void)copy_to_gpa(vm, sw_kernel->kernel_src_addr,
+	ret = copy_to_gpa(vm, sw_kernel->kernel_src_addr,
 		(uint64_t)sw_kernel->kernel_load_addr, sw_kernel->kernel_size);
+	if (ret != 0) {
+		pr_err("Copying guest kernel image to 0x%016lx failed",
+			sw_kernel->kernel_load_addr);
+		return -EACCES;
+	}
 
 	/* Check if a RAM disk is present */
 	if (ramdisk_info->size != 0U) {
 		/* Copy RAM disk to its load location */
-		(void)copy_to_gpa(vm, ramdisk_info->src_addr,
+		ret = copy_to_gpa(vm, ramdisk_info->src_addr,
 			(uint64_t)ramdisk_info->load_addr,
 			ramdisk_info->size);
+		if (ret != 0) {
+			pr_err("Copying RAM disk to 0x%016lx failed",
+				ramdisk_info->load_addr);
+			return -EACCES;
+		}
 	}
 	/* Copy Guest OS bootargs to its load location */
 	if (bootargs_info->size != 0U) {
-		(void)copy_to_gpa(vm, bootargs_info->src_addr,
+		ret = copy_to_gpa(vm, bootargs_info->src_addr,
 			(uint64_t)bootargs_info->load_addr,
-			(strnlen_s((char *)bootargs_info->src_addr, MAX_BOOTARGS_SIZE) + 1U));
+			(strnlen_s((char *)bootargs_info->src_addr,
+				MAX_BOOTARGS_SIZE) + 1U));
+		if (ret != 0) {
+			pr_err("Copying Guest OS bootargs to 0x%016lx failed",
+				bootargs_info->load_addr);
+			return -EACCES;
+		}
 	}
 	switch (vm->sw.kernel_type) {
 	case KERNEL_BZIMAGE:
